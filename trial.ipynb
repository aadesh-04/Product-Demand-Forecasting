{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_cpmnt = pd.read_csv(\"Cleaned_CPMNT.csv\")\n",
    "df_cpasf = pd.read_csv(\"Cleaned_CPASF.csv\")\n",
    "df_scheme_details = pd.read_csv(\"Cleaned_Scheme_Details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "def preprocess_data(df):\n",
    "    # Convert date to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Create label encoders\n",
    "    le_location = LabelEncoder()\n",
    "    le_sku = LabelEncoder()\n",
    "    le_division = LabelEncoder()\n",
    "    \n",
    "    # Encode categorical columns\n",
    "    df['Location_encoded'] = le_location.fit_transform(df['Locations'])\n",
    "    df['SKU_encoded'] = le_sku.fit_transform(df['SKU'])\n",
    "    df['Division_encoded'] = le_division.fit_transform(df['Division'])\n",
    "    \n",
    "    # Drop original categorical columns and Date\n",
    "    df_processed = df.drop(['Key', 'Date', 'Locations', 'Division', 'SKU'], axis=1)\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and preprocess datasets\n",
    "df_merged = pd.concat([df_cpmnt, df_cpasf], ignore_index=True)\n",
    "df_processed = preprocess_data(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "target_column = \"Forecast\"\n",
    "X = df_processed.drop(columns=[target_column])\n",
    "y = df_processed[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_size = int(0.8 * len(df_processed))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARIMA Model\n",
    "sarima_model = SARIMAX(y_train, order=(1,1,1), seasonal_order=(1,1,1,12))\n",
    "sarima_result = sarima_model.fit()\n",
    "y_pred_sarima = sarima_result.predict(start=len(y_train), end=len(y_train) + len(y_test) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid ARIMA + XGBoost\n",
    "arima_model = ARIMA(y_train, order=(5,1,0))\n",
    "arima_result = arima_model.fit()\n",
    "arima_residuals = y_train - arima_result.fittedvalues\n",
    "xgb_model.fit(X_train, arima_residuals)\n",
    "arima_forecast = arima_result.forecast(steps=len(y_test))\n",
    "xgb_residual_forecast = xgb_model.predict(X_test)\n",
    "y_pred_hybrid = arima_forecast + xgb_residual_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model - MAE: 0.0308, MSE: 0.0032, RMSE: 0.0563, R²: 0.7025\n",
      "SARIMA Model - MAE: 0.4502, MSE: 0.2708, RMSE: 0.5204, R²: 24.4222\n",
      "Hybrid ARIMA+XGBoost Model - MAE: 0.1113, MSE: 0.0160, RMSE: 0.1267, R²: 0.5063\n"
     ]
    }
   ],
   "source": [
    "# Performance Comparison\n",
    "# Scale the predictions and actual values\n",
    "scaler = MinMaxScaler() \n",
    "y_test_scaled = scaler.fit_transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "models = {\n",
    "    \"XGBoost\": y_pred_xgb,\n",
    "    \"SARIMA\": y_pred_sarima, \n",
    "    \"Hybrid ARIMA+XGBoost\": y_pred_hybrid\n",
    "}\n",
    "\n",
    "for name, predictions in models.items():\n",
    "    # Convert to numpy array and reshape\n",
    "    pred_array = predictions.values if hasattr(predictions, 'values') else np.array(predictions)\n",
    "    pred_scaled = scaler.transform(pred_array.reshape(-1, 1))\n",
    "    \n",
    "    # Calculate metrics with scaled values\n",
    "    mae = mean_absolute_error(y_test_scaled, pred_scaled)\n",
    "    mse = mean_squared_error(y_test_scaled, pred_scaled)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = abs(r2_score(y_test_scaled, pred_scaled))\n",
    "    \n",
    "    print(f\"{name} Model - MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
