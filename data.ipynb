{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "file_cpasf = \"Cleaned_CPASF.csv\"\n",
    "file_cpmnt = \"Cleaned_CPMNT.csv\"\n",
    "file_scheme_details = \"SCHEME DETAILS.xlsx\"\n",
    "\n",
    "df_cpasf = pd.read_csv(file_cpasf)\n",
    "df_cpmnt = pd.read_csv(file_cpmnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' column to datetime format\n",
    "df_cpasf['Date'] = pd.to_datetime(df_cpasf['Date'])\n",
    "df_cpmnt['Date'] = pd.to_datetime(df_cpmnt['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SCHEME DETAILS.xlsx and process all sheets\n",
    "xls = pd.ExcelFile(file_scheme_details)\n",
    "sheet_names = xls.sheet_names\n",
    "sheets_data = {sheet: pd.read_excel(xls, sheet_name=sheet) for sheet in sheet_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_scheme_data(df):\n",
    "    df = df.dropna(how='all')  # Remove completely empty rows\n",
    "    df.columns = df.iloc[0]  # Set the first row as header\n",
    "    df = df[1:].reset_index(drop=True)  # Remove the first row and reset index\n",
    "    \n",
    "    # Convert column names to strings before stripping whitespace\n",
    "    df = df.rename(columns=lambda x: str(x).strip() if pd.notna(x) else x)\n",
    "    \n",
    "    # Extract numerical discount values using regex\n",
    "    df['Discount'] = df.iloc[:, 4].astype(str).apply(lambda x: re.findall(r'\\d+\\.?\\d*%', x))\n",
    "    df['Discount'] = df['Discount'].apply(lambda x: x[0] if x else None)\n",
    "    \n",
    "    # Convert scheme period to start and end date\n",
    "    df['Scheme Start'] = df.iloc[:, 2]\n",
    "    df['Scheme End'] = df.iloc[:, 3]\n",
    "    df['Scheme Start'] = pd.to_datetime(df['Scheme Start'], errors='coerce')\n",
    "    df['Scheme End'] = pd.to_datetime(df['Scheme End'], errors='coerce')\n",
    "    \n",
    "    return df[['DATE', 'PRODUCT/PACK', 'Scheme Start', 'Scheme End', 'Discount', 'LOCATION/CLUSTER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1062734766.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Scheme Start'] = pd.to_datetime(df['Scheme Start'], errors='coerce')\n",
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1062734766.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Scheme End'] = pd.to_datetime(df['Scheme End'], errors='coerce')\n",
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1062734766.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Scheme Start'] = pd.to_datetime(df['Scheme Start'], errors='coerce')\n",
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1062734766.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Scheme End'] = pd.to_datetime(df['Scheme End'], errors='coerce')\n",
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1062734766.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Scheme Start'] = pd.to_datetime(df['Scheme Start'], errors='coerce')\n",
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1062734766.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Scheme End'] = pd.to_datetime(df['Scheme End'], errors='coerce')\n",
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1062734766.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Scheme Start'] = pd.to_datetime(df['Scheme Start'], errors='coerce')\n",
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1062734766.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Scheme End'] = pd.to_datetime(df['Scheme End'], errors='coerce')\n",
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1062734766.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Scheme Start'] = pd.to_datetime(df['Scheme Start'], errors='coerce')\n",
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1062734766.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Scheme End'] = pd.to_datetime(df['Scheme End'], errors='coerce')\n",
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1062734766.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Scheme Start'] = pd.to_datetime(df['Scheme Start'], errors='coerce')\n",
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1062734766.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Scheme End'] = pd.to_datetime(df['Scheme End'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Process all sheets\n",
    "processed_sheets = {sheet: clean_scheme_data(sheets_data[sheet]) for sheet in sheet_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all structured data into a single DataFrame\n",
    "scheme_data_final = pd.concat(processed_sheets.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and cleaned scheme details saved to Cleaned_Scheme_Details.csv\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned scheme details\n",
    "scheme_data_final.to_csv(\"Cleaned_Scheme_Details.csv\", index=False)\n",
    "\n",
    "print(\"Processed and cleaned scheme details saved to Cleaned_Scheme_Details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned scheme details file\n",
    "df_scheme = pd.read_csv(\"Cleaned_Scheme_Details.csv\")\n",
    "\n",
    "def clean_fully_scheme_details(df):\n",
    "    # Fill missing values using forward-fill where applicable\n",
    "    df['DATE'] = df['DATE'].fillna(method='ffill')\n",
    "    df['PRODUCT/PACK'] = df['PRODUCT/PACK'].fillna(method='ffill')\n",
    "    df['LOCATION/CLUSTER'] = df['LOCATION/CLUSTER'].fillna(\"UNKNOWN\")\n",
    "    \n",
    "    # Fill missing discount values with 'No Discount'\n",
    "    df['Discount'] = df['Discount'].fillna(\"No Discount\")\n",
    "    \n",
    "    # Convert scheme period to datetime format\n",
    "    df['Scheme Start'] = pd.to_datetime(df['Scheme Start'], errors='coerce')\n",
    "    df['Scheme End'] = pd.to_datetime(df['Scheme End'], errors='coerce')\n",
    "    \n",
    "    # Fill missing scheme start and end dates logically\n",
    "    df['Scheme Start'] = df['Scheme Start'].fillna(method='ffill')\n",
    "    df['Scheme End'] = df['Scheme End'].fillna(method='ffill')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1681325607.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['DATE'] = df['DATE'].fillna(method='ffill')\n",
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1681325607.py:7: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['PRODUCT/PACK'] = df['PRODUCT/PACK'].fillna(method='ffill')\n",
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1681325607.py:18: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Scheme Start'] = df['Scheme Start'].fillna(method='ffill')\n",
      "C:\\Users\\sunil\\AppData\\Local\\Temp\\ipykernel_21676\\1681325607.py:19: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Scheme End'] = df['Scheme End'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Apply cleaning function\n",
    "df_scheme = clean_fully_scheme_details(df_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fully cleaned data\n",
    "df_scheme.to_csv(\"Fully_Cleaned_Scheme_Details.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'DATE' column\n",
    "df_scheme.drop(columns=['DATE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode products (Prod A to Prod E)\n",
    "for prod in ['Prod A', 'Prod B', 'Prod C', 'Prod D', 'Prod E']:\n",
    "    df_scheme[prod] = df_scheme['PRODUCT/PACK'].apply(lambda x: 1 if prod in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City Mapping for encoding\n",
    "city_mappings = {\n",
    "    \"BGLR\": \"Bangalore\", \"CAL\": \"Calcutta\", \"MUM\": \"Mumbai\", \"CHN\": \"Chennai\",\n",
    "    \"DEL\": \"Delhi\", \"HYD\": \"Hyderabad\", \"KOL\": \"Kolkata\"\n",
    "}\n",
    "\n",
    "def process_location(location):\n",
    "    if pd.isna(location) or location == \"UNKNOWN\":\n",
    "        return None\n",
    "    location = location.upper()\n",
    "    for short, full in city_mappings.items():\n",
    "        location = location.replace(short, full)\n",
    "    if \"ALL INDIA\" in location:\n",
    "        return \"All Cities\"\n",
    "    return location.split()[0]  # Extract first city name only\n",
    "\n",
    "df_scheme['City'] = df_scheme['LOCATION/CLUSTER'].apply(process_location)\n",
    "df_scheme = df_scheme.dropna(subset=['City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for cities\n",
    "df_cities = pd.get_dummies(df_scheme['City'])\n",
    "df_scheme = pd.concat([df_scheme, df_cities], axis=1)\n",
    "\n",
    "df_scheme.to_csv(\"Final_Cleaned_Scheme_Details.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
